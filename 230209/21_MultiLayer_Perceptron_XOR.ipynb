{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af1fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b3509",
   "metadata": {},
   "source": [
    "XOR 연산은 입력 데이터를 X라고 할 경우 [[0, 0], [0, 1], [1, 0], [1, 1]]과 같은 경우의 수가 있다.  \n",
    "총 4개의 데이터가 각각 2개의 특성을 가지고 있으므로 X는 [4, 2]의 형태로 정의할 수 있다.  \n",
    "입력값에 따른 출력값 Y는 [[0], [1], [1], [0]]이므로 Y는 [4, 1]의 형태로 정의할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9ede7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[4, 2]) # 입력값\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[4, 1]) # 출력값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910610a",
   "metadata": {},
   "source": [
    "1번째 히든 레이어에서 2개의 입력(X)과 1개의 편향값(B1)을 받아서 2개의 시그모이드 출력(Z)을 다음 레이어로 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facfbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 입력을 받는 2개의 뉴런을 만든다.\n",
    "# random_normal()은 정규 분포로 부터 난수값을 반환하고 random_uniform()은 균등 분포로 부터의 난수값을 반환한다.\n",
    "W1 = tf.Variable(tf.random_uniform([2, 2]))\n",
    "# 각 뉴런은 1개의 편향값을 가진다.\n",
    "# zeros()는 모든 원소의 값이 0인 텐서를 생성한다.\n",
    "B1 = tf.Variable(tf.zeros([2]))\n",
    "# 시그모이드를 거쳐 출력값으로 Z를 리턴한다. => sigmoid(W1 * X + B1)\n",
    "Z = tf.sigmoid(tf.matmul(X, W1) + B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d625745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5702385  0.43660235]\n",
      " [0.01707244 0.96797216]]\n",
      "[0. 0.]\n",
      "[[0.5        0.5       ]\n",
      " [0.504268   0.7247151 ]\n",
      " [0.63881814 0.6074491 ]\n",
      " [0.6427479  0.8029088 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(W1))\n",
    "print(sess.run(B1))\n",
    "train_X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "print(sess.run(Z, feed_dict={X: train_X}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925a74a",
   "metadata": {},
   "source": [
    "2번째 히든 레이어에서 1번째 히든 레이어의 출려값인 Z와 1개의 편향값(B2)을 받아서 1개의 시그모이드를 출력(Y_hat)한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fe9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z를 입력값으로 받는 1개의 뉴런을 만든다.\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1]))\n",
    "# 각 뉴런은 1개의 편향값을 가진다.\n",
    "B2 = tf.Variable(tf.zeros([1]))\n",
    "# 시그모이드를 거쳐 출력값으로 Y_hat을 리턴한다. => sigmoid(W2 * Z + B1)\n",
    "Y_hat = tf.sigmoid(tf.matmul(Z, W2) + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627e0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4976982 ]\n",
      " [0.10419202]]\n",
      "[0.]\n",
      "[[0.57467353]\n",
      " [0.5823629 ]\n",
      " [0.58655703]\n",
      " [0.59385383]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(W2))\n",
    "print(sess.run(B2))\n",
    "print(sess.run(Y_hat, feed_dict={X: train_X}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7de87",
   "metadata": {},
   "source": [
    "손실 함수로 크로스 엔트로피를 사용하고 경사 하강법으로 모델의 매개 변수(가중치, 편향)을 최적화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cba966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크로스 엔트로피\n",
    "loss = tf.reduce_mean(\n",
    "    -1 * (Y * tf.log(Y_hat) + (1 - Y) * tf.log(1.0 - Y_hat))\n",
    ")\n",
    "\n",
    "# 경사하강법\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# 모델을 학습하기 위한 데이터를 만든다.\n",
    "train_X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "train_Y = [[0], [1], [1], [0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c41e6",
   "metadata": {},
   "source": [
    "학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3318de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터: [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
      "================================================================================\n",
      "epoch: 0\n",
      "output\n",
      " [[0.66129833]\n",
      " [0.68251884]\n",
      " [0.71302533]\n",
      " [0.7291868 ]]\n",
      "================================================================================\n",
      "epoch: 2000\n",
      "output\n",
      " [[0.3899938 ]\n",
      " [0.546663  ]\n",
      " [0.5298093 ]\n",
      " [0.56580526]]\n",
      "================================================================================\n",
      "epoch: 4000\n",
      "output\n",
      " [[0.13644484]\n",
      " [0.77738917]\n",
      " [0.77203375]\n",
      " [0.34126437]]\n",
      "================================================================================\n",
      "epoch: 6000\n",
      "output\n",
      " [[0.05151135]\n",
      " [0.95177066]\n",
      " [0.95201623]\n",
      " [0.05848521]]\n",
      "================================================================================\n",
      "epoch: 8000\n",
      "output\n",
      " [[0.02902457]\n",
      " [0.9759712 ]\n",
      " [0.9760653 ]\n",
      " [0.02734044]]\n",
      "================================================================================\n",
      "epoch: 10000\n",
      "output\n",
      " [[0.01996744]\n",
      " [0.9842706 ]\n",
      " [0.98432124]\n",
      " [0.01739767]]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('학습데이터: {}'.format(train_X))\n",
    "    print('=' * 80)\n",
    "    \n",
    "    for epoch in range(10001):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if epoch % 2000 == 0:\n",
    "            print('epoch: {}'.format(epoch))\n",
    "            print('output\\n', sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))\n",
    "            print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9e0e4",
   "metadata": {},
   "source": [
    "학습 결과를 통해 [0, 0], [1, 1]은 0에 상당히 가까운 값을 출력하고 [0, 1], [1, 0]은 1에 가까운 값을 출력하는 것을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
